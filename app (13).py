# -*- coding: utf-8 -*-
"""APP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fv60wGmH3DjUmabGwngiHShA-_xjCycV
"""

import streamlit as at
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

"""##LOAD THE DATASET"""

google =pd.read_csv('/content/google_ads-sheet1-sourcetable (1).csv')
LikedIn= pd.read_csv('/content/linked_in_campaigns-sheet1-sourcetable (1).csv')
Meta_ads= pd.read_csv('/content/meta_ads_campaigns-sheet1-sourcetable.csv')

import streamlit as st
st.set_page_config(page_title="Ad Profit AI", layout="wide")
st.title("Ad Profit AI – Instant Ad Money Leak Detector")
st.markdown("**Upload your Google, LinkedIn, and Meta ad CSV files to analyze performance**")

"""3File uploader"""

uploaded_files = st.file_uploader("Upload your ad CSV files", type=["csv"], accept_multiple_files=True)

if not uploaded_files:
    st.info("Please upload one or more CSV files containing your advertising data to begin analysis.")
    st.stop()

# Process uploaded files
try:
    # Read all uploaded files
    dataframes = []
    for uploaded_file in uploaded_files:
        df = pd.read_csv(uploaded_file)
        dataframes.append(df)

    if not dataframes:
        st.error("No valid data was found in the uploaded files.")
        st.stop()

    # For simplicity, combine all uploaded files into a single dataframe
    # In a production version, you would want more sophisticated merging logic
    df = pd.concat(dataframes, ignore_index=True)

except Exception as e:
    st.error(f"An error occurred while processing the uploaded files: {str(e)}")
    st.stop()

# Clean and standardize the data
def clean_and_standardize(df):
    # Clean currency columns - try multiple possible column names
    spend_columns = ['Cost', 'Amount spent', 'Total Spent (USD)', 'Spend']
    revenue_columns = ['Purchase value', 'Revenue', 'Value']

    spend_col = None
    for col in spend_columns:
        if col in df.columns:
            spend_col = col
            break

    if spend_col:
        df['Spend'] = df[spend_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    else:
        df['Spend'] = 0

    revenue_col = None
    for col in revenue_columns:
        if col in df.columns:
            revenue_col = col
            break

    if revenue_col:
        df['Revenue'] = df[revenue_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
    else:
        df['Revenue'] = 0

    # Handle conversions
    conversion_columns = ['Conversions', 'Leads', 'Purchases']
    conversion_col = None
    for col in conversion_columns:
        if col in df.columns:
            conversion_col = col
            break

    if conversion_col:
        df['Conversions'] = pd.to_numeric(df[conversion_col], errors='coerce').fillna(0)
    else:
        df['Conversions'] = 0

    # Set platform if not already present
    if 'Platform' not in df.columns:
        df['Platform'] = 'Uploaded Data'

    # Calculate ROAS
    df['ROAS'] = np.where(df['Spend'] > 0, df['Revenue'] / df['Spend'], 0)

    return df

"""##Aply clustering and  standadlization"""

df = pd.concat([google, LikedIn, Meta_ads], ignore_index=True)
df = clean_and_standardize(df)

"""##Machine learning segmemtation"""

features = ['Spend', 'Conversions', 'Revenue', 'ROAS']
X = df[features].fillna(0)
X_scaled = StandardScaler().fit_transform(X)
df['Segment'] = KMeans(n_clusters=4, random_state=42, n_init=10).fit_predict(X_scaled)

"""#Display Features"""

col1, col2, col3, col4 = st.columns(4)
col1.metric("Total Spend", f"${df['Spend'].sum():,.0f}")
col2.metric("Total Revenue", f"${df['Revenue'].sum():,.0f}")
col3.metric("Profit", f"${df['Revenue'].sum() - df['Spend'].sum():,.0f}")
col4.metric("Average ROAS", f"{df['ROAS'].mean():.2f}x")

"""#Identify bleeding  campaigns"""

bleeding_campaigns = df[(df['Spend'] > 200) & (df['Conversions'] == 0) & (df['Revenue'] == 0)]
if len(bleeding_campaigns) > 0:
    st.error(f"⚠️ CRITICAL: {len(bleeding_campaigns)} campaigns are wasting ${bleeding_campaigns['Spend'].sum():,.0f} with zero conversions and revenue. These should be paused immediately.")

"""#Visualization"""

fig = px.scatter(df, x="Spend", y="Revenue", color="Platform", size="ROAS",
                 hover_data=['Conversions'],
                 title="Ad Performance Analysis: Spend vs Revenue")
st.plotly_chart(fig, use_container_width=True)

st.success("Analysis completed successfully!")