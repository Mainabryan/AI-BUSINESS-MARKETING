# -*- coding: utf-8 -*-
"""APP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NttdR--YJ5N-isPA6XJ3J6HMepKl63Py
"""

import sys

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="Ad Profit AI", layout="wide")
st.title("Ad Profit AI – Instant Ad Money Leak Detector")
st.markdown("Upload your Google, LinkedIn, and Meta ad CSV files to analyze performance")

# File uploader
uploaded_files = st.file_uploader("Upload your ad CSV files", type=["csv"], accept_multiple_files=True)

# Initialize df to None. This ensures 'df' is always declared, preventing NameError.
df = None

if not uploaded_files:
    st.info("Please upload one or more CSV files containing your advertising data to begin analysis.")
    # The rest of the script will not run the analysis part because df remains None.
else:
    # Process only the uploaded files
    try:
        # Read all uploaded files
        dataframes = []
        for uploaded_file in uploaded_files:
            df_temp = pd.read_csv(uploaded_file)
            dataframes.append(df_temp)

        if not dataframes:
            st.error("No valid data was found in the uploaded files.")
            # df remains None, so the analysis part won't run.
        else:
            # Combine all uploaded files into a single dataframe
            df = pd.concat(dataframes, ignore_index=True)

    except Exception as e:
        st.error(f"An error occurred while processing the uploaded files: {str(e)}")
        df = None # Explicitly set df to None if an error occurs

# Only proceed with the analysis if 'df' has been successfully populated and is not empty
if df is not None and not df.empty:

    # Clean and standardize the data
    def clean_and_standardize(df_to_clean):
        # Clean currency columns - try multiple possible column names
        spend_columns = ['Cost', 'Amount spent', 'Total Spent (USD)', 'Spend']
        revenue_columns = ['Purchase value', 'Revenue', 'Value']

        spend_col = None
        for col in spend_columns:
            if col in df_to_clean.columns:
                spend_col = col
                break

        if spend_col:
            df_to_clean['Spend'] = df_to_clean[spend_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
        else:
            df_to_clean['Spend'] = 0

        revenue_col = None
        for col in revenue_columns:
            if col in df_to_clean.columns:
                revenue_col = col
                break

        if revenue_col:
            df_to_clean['Revenue'] = df_to_clean[revenue_col].astype(str).str.replace(r'[$,]', '', regex=True).astype(float)
        else:
            df_to_clean['Revenue'] = 0

        # Handle conversions
        conversion_columns = ['Conversions', 'Leads', 'Purchases']
        conversion_col = None
        for col in conversion_columns:
            if col in df_to_clean.columns:
                conversion_col = col
                break

        if conversion_col:
            df_to_clean['Conversions'] = pd.to_numeric(df_to_clean[conversion_col], errors='coerce').fillna(0)
        else:
            df_to_clean['Conversions'] = 0

        # Set platform if not already present
        if 'Platform' not in df_to_clean.columns:
            df_to_clean['Platform'] = 'Uploaded Data'

        # Calculate ROAS
        df_to_clean['ROAS'] = np.where(df_to_clean['Spend'] > 0, df_to_clean['Revenue'] / df_to_clean['Spend'], 0)

        return df_to_clean

    # Apply cleaning and standardization to the uploaded data only
    df = clean_and_standardize(df)

    # Machine learning segmentation
    features = ['Spend', 'Conversions', 'Revenue', 'ROAS']
    X = df[features].fillna(0)
    X_scaled = StandardScaler().fit_transform(X)
    df['Segment'] = KMeans(n_clusters=4, random_state=42, n_init=10).fit_predict(X_scaled)

    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Total Spend", f"${df['Spend'].sum():,.0f}")
    col2.metric("Total Revenue", f"${df['Revenue'].sum():,.0f}")
    col3.metric("Profit", f"${df['Revenue'].sum() - df['Spend'].sum():,.0f}")
    col4.metric("Average ROAS", f"{df['ROAS'].mean():.2f}x")

    # Identify bleeding campaigns
    bleeding_campaigns = df[(df['Spend'] > 200) & (df['Conversions'] == 0) & (df['Revenue'] == 0)]
    if len(bleeding_campaigns) > 0:
        st.error(f"⚠️ CRITICAL: {len(bleeding_campaigns)} campaigns are wasting ${bleeding_campaigns['Spend'].sum():,.0f} with zero conversions and revenue. These should be paused immediately.")

    # Visualization
    fig = px.scatter(df, x="Spend", y="Revenue", color="Platform", size="ROAS",
                     hover_data=['Conversions'],
                     title="Ad Performance Analysis: Spend vs Revenue")
    st.plotly_chart(fig, use_container_width=True)

    st.success("Analysis completed successfully!")